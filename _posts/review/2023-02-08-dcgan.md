---
author_profile: false
title:  "DCGAN 논문 리뷰"
excerpt: "Deeo Convolutional Generative Adversarial Networks"
categories:
  - 논문 리뷰
tags:
  - DCGAN
  - 리뷰
  - 논문
  - review
last_modified_at: 2023-02-08T08:06:00-05:00
---


|                    |                                      |
| ------------------ | ------------------------------------ |
| 태그               | Generative Model                     |
| Description        | DCGAN                                |
| Journal/Conference | ICLR                                 |
| Link               | https://arxiv.org/abs/1511.06434     |
| Year               | 2016                                 |
| 원문 링크          | https://arxiv.org/pdf/1511.06434.pdf |


<br/>
<br/>
<br/>

### Deep Convolutional Generative Adversarial Networks
(심층 합성곱 생성적 적대 신경망)

<img src="https://charcoalskies.github.io/images/3.DCGAN/1.DCGAN_Model.png">

<br/>
<br/>
<br/>

### 요약 

DCGAN은 GAN의 개선 모델로 GAN과 다른 점은 다음과 같다

<br/>

- D(Discriminator)
	- Strided Convolution을 사용
	- Batch Normalization을 사용. 입력 레이어 (첫번째)에는 사용하지 않는다
	- activation function으로 Leaky ReLU를 사용

- G(Generator) 
	- Fractional Strided Convolution(Transposed Convolution)을 사용
	- Batch Normalization을 사용. 출력 레이어(마지막)에는 사용하지 않는다.
	- activation function으로 ReLU를 사용하고 마지막 레이어는 tanh를 사용

<br/>

$\star$논문에서 deconvolution이라 되어 있는 것은 Transposed 또는 fractional strided convolution을 의미. 이 연산은 convolution의 역연산이 아님

<br/>
<br/>
<br/>
<br/>
<br/>

### GAN Review

![](https://user-images.githubusercontent.com/55128069/218314641-a397899e-0654-4081-986b-82e244ec19f8.png)

![](https://user-images.githubusercontent.com/55128069/218314671-d323cb93-6db6-466c-a911-698ab86fb8c4.png)

![GAN_이론공식](https://user-images.githubusercontent.com/55128069/218314689-2c8e8ce3-2995-4261-8b6c-4b43cc59b5ff.png)

<br/>
<br/>
<br/>
<br/>
<br/>

### 기존 GAN의 한계

<br/>

1. GAN의 결과가 불안정하다
	- 기존 GAN만 으로는 성능이 잘 나오지 않았다

<br/>

2. Black-box method
	- Neural Network 자체의 한계라고 볼 수 있는데, 결정 변수나 주요 변수를 알 수 있는 다수의 머신러닝 기법들과 달리 Neural Network는 처음부터 끝까지 어떤 형태로 그러한 결과가 나오게 되었는지 그 과정을 알 수 없다.

<br/>

3. Generative Model 평가
	- GAN은 결과물 자체가 새롭게 만들어진 Sample이다. 이를 기존 sample과 비교하여 얼마나 비슷한지 확인할 수 있는 정략적 척도가 없고, 사람이 판단하더라도 이는 주관적인 기준이기 때문에 얼마나 정확한지, 혹은 뛰어난지 판단하기 힘들다


<br/>
<br/>
<br/>
<br/>
<br/>

### DCGAN의 목표

1. Generator가 단순 기억으로 generate하지 않는다는 것을 보여줘야 한다. 
2.  z(sampling 된 noise vector) 의 미세한 변동에 따른 generator 결과가 연속적으로 부드럽게 이어져야 한다. (이를 walking in the latent space라고 한다.)


<br/>
<br/>
<br/>
<br/>
<br/>

### Architecture Guidelines

<br/>

GAN과 DCGAN의 전체적인 구조는 거의 유사. 

<br/>

다만 각각의 Discriminator와 Generator의 세부적인 구조가 달라진다.

<br/>

논문발췌

``` txt
GAN에 CNN을 써서 이미지 품질을 높이려는 시도는 지금까지 성공적이지 못했다.

우리는 많은 시도 끝에 다양한 데이터셋에서 안정적인 그리고 더 높은 해성도의 이미지를 생성하는 모델 구조를 찾아내었다. 핵심은 다음 3가지를 CNN구조에 적용시키는 것이다.

1. max-pooling 과 같은 미분불가능한 레이어를 strided convolution으로 바꿔 
	spatial downsampling이 가능하게 한 것이다. 이는 G에 사용된 것이고, D에는 
	unsampling 이 가능하게 바꿨다

2. 요즘 트랜드는 FC(Fully Connected) Layer를 없애고 convolution layer로 바꾸는 것.

3. Batch Normalization을 사용하여 학습을 안정화시킨다
	(*2019년 현재 BN은 거의 필수처럼 되어 있다.) 
	이는 weight 초기화가 나쁘게 된 경우와 깊은 모델에서 gradient flow를 도우며,
	이는 학습 초기에 잘못된 방향으로 학습이 진행되어 망해가는 경우를 막아준다.

	그러나 sample이 요동치는 것을 막기 위해 G의 출력 레어이어와 D의 input layer에 
	는 넣지 않았다.(수많은 시도 끝에 알아냄)


G에서는 activation function으로 ReLU를 사용하고 마지막 레이어에는 tanh를 사용한다. Bounded activation(tanh)은 더 빠르게 수렴하고 학습샘플의 분포를 따라갔다. 
D에는 Leaky ReLU를 사용하여 높은 해상도를 만들 수 있게 하였다. 

이는 GAN과 다른 부분이다. 
```

<br/>
<br/>
<br/>
<br/>
<br/>


### 기존 GAN Architecture

![gan-architecture](https://user-images.githubusercontent.com/55128069/218314775-8f8d48bf-b0e4-4a1b-9c35-94b796628baa.png)

<br/>
<br/>
<br/>
<br/>
<br/>

### CNN Architecture

![](https://user-images.githubusercontent.com/55128069/218314773-c4f64637-3f53-4c79-94eb-0e99819f0c71.png)

<br/>
<br/>
<br/>
<br/>
<br/>

### DCGAN Architecture

<br/>

DCGAN은 결국, 기존 GAN에 존재했던 fully-connected 구조의 대부분을 CNN구조로 대체한것.

![](https://user-images.githubusercontent.com/55128069/218314822-2a3d8708-2728-4ab2-9ccd-6f87f8874146.png)

<br/>

- Discriminator에서는 모든 pooling layers를 strided convolutions로 바꾸고, Generator에서는 pooling layers를 fractional-strided convolution으로 바꾼다.

<br/>

- Generator와 Discriminator에 batch-normalization을 사용한다. 논문에서는 이를 통해deep generators의 초기 실패를 막는다고 하였다. 그러나 모든 layer에 다 적용하면 sample oscillation과 model instability의 문제가 발생하여 Generator output layer와 Discriminator input layer에는 적용하지 않았다고 한다.

<br/>

- Fully-connected hidden layers를 삭제한다.

<br/>

- Generator에서 모든 활성화 함수는 ReLU를 쓰되, 마지막 출력단에서만 Tanh를 사용한다.

<br/>

- Discriminator에서는 모든 활성화 함수를 LeakyReLU를 사용한다.


<br/>
<br/>
<br/>
<br/>
<br/>


#### Strided Convolution이란?
![padding_strides](https://user-images.githubusercontent.com/55128069/218314849-cae9dea2-2086-4b60-9f08-6bffdca0cd27.gif)


<br/>
<br/>
<br/>
<br/>
<br/>

#### Fractionally-Strided Convolution이란?
![padding_strides_transposed](https://user-images.githubusercontent.com/55128069/218314868-85913627-98c1-48d7-be27-7335c1359819.gif)


둘의 차이

기존 convolutions는 필터를 거치며 크기가 작아진 반면에 fractionally-strided convolution은 input에 padding을 하고 convolution을 수행하며 오히려 필터가 더 커지는 특징이 차이점 이다.

<br/>

쉽게 transposed convolution이라고 불린다 논문에서는 Deconvolution이라고 불리는데 이는 잘못된 단어라고 한다.

<br/>
<br/>
<br/>
<br/>
<br/>

용어 설명

--- 

### Batch-normalization이란?

<br/>

Batch Normalization은 최근 거의 모든 인경신경망에 쓰이고 있는 기법

기본적으로 Gradient Vanishing / Gradient Exploding이 일어나지 않도록 하는 아이디어 중의 하나이며, 

지금까지는 이 문제를 Activation함수의 변화(ReLU 등), Careful Initialization, small learning rate 등으로 해결했지만, 이 논문에서는 이러한 간접적인 방법보다 training하는 과정 자체를 전체적으로 안정화하여 학습 속도를 가속시킬 수 있는 근본적인 방법을 제안하였다.

<br/>
<br/>
<br/>
<br/>
<br/>


### **Gradient Vanishing / Exploding 문제**

<br/>

신경망에서 학습시 Gradient 기반의 방법들은 파라미터 값의 작은 변화가 신경망 출력에 얼마나 영향을 미칠 것인가를 기반으로 파라미터 값을 학습시키게 된다. 

만약 파라미터 값의 변화가 신경망 결과의 매우 작은 변화를 미치게 될 경우 파라미터를 효과적으로 학습 시킬 수 없게 된다.

<br/>
<br/>
<br/>

**Gradient 라는 것이 결국 미분값 즉 변화량을 의미하는데 이 변화량이 매우 작아지거나(Vanishing) 커진다면(Exploding) 신경망을 효과적으로 학습시키지 못하고, Error rate 가 낮아지지 않고 수렴해버리는 문제가 발생** 하게 된다. 

그래서 이러한 문제를 해결하기 위해서 Sigmoid 나 tanh 등의 활성화 함수들은 매우 비선형적인 방식으로 입력 값을 매우 작은 출력 값의 범위로 squash 해버리는데, 가령 sigmoid는 실수 범위의 수를 [0, 1]로 맵핑해버린다. 

이렇게 출력의 범위를 설정할 경우, 매우 넓은 입력 값의 범위가 극도로 작은 범위의 결과 값으로 매핑된다. 

이러한 현상은 비선형성 레이어들이 여러개 있을 때 더욱 더 효과를 발휘하여(?) 학습이 악화된다. 

**첫 레이어의 입력 값에 대해 매우 큰 변화량이 있더라도 결과 값의 변화량은 극소가 되어버리는 것이다.** 

그래서 이러한 문제점을 해결하기 위해 활성화 함수로 자주 쓰이는 것이 **ReLU(Rectified Linear Unit)** 이다. 또한 아래와 같은 방법들도 존재한다. 

-   **Change activation function** : 활성화 함수 중 Sigmoid 에서 이 문제가 발생하기 때문에 ReLU 를 사용
-   **Careful initialization** : 가중치 초기화를 잘 하는 것을 의미
-   **Small learning rate** : Gradient Exploding 문제를 해결하기 위해 learning rate 값을 작게 설정함

---


<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

### Generator Model 

![](https://user-images.githubusercontent.com/55128069/218314590-a86288da-5356-478e-8ce2-c042ac1700e6.png)

100 dimensional uniform distribution(Z) 이 들어오면 이들이 4개의 fractionally-strided convolution layer를 거치며 크기를 키워서 더 높은 차원의 64 x 64 pixel 이미지가 된다.


<br/>
<br/>
<br/>
<br/>
<br/>


### Visualization 

**Generated bedrooms**

![](https://user-images.githubusercontent.com/55128069/218315369-3e2c0445-137b-4358-879a-a5bbf7d93809.png)

<br/>
<br/>
<br/>

**Walking in the latent space**
![4 Figure_4](https://user-images.githubusercontent.com/55128069/218315384-334de164-e51d-4b5b-8b66-57bd32b62962.png)

앞서 DCGAN의 목표들 중 하나인 walking in the latent space를 직접 구현한 그림.

생성된 2개의 이미지에 사용된 noise인 $z$ 를 선형 보간하며 그 보간된 $z$ 로 이미지를 생성시켜본  결과 한 이미지에서 다른 이미지로 서서히 변해가는 결과를 얻었다. 
이미지를 보면 창문 없는 방이 거대한 창문이 있는 방으로 변해가거나, TV가 창문으로 변해가는 과정을 볼 수 있다.


<br/>
<br/>
<br/>

**Visualize filters (no longer black-box)**
![5 Figure_5](https://user-images.githubusercontent.com/55128069/218315386-4ff812e9-525a-4cf6-9d62-9cc6feaa418b.png)

네트워크 내부의 각 필터는 이해할 수 없는 형식이 아닌 특정 object나 특징을 추출하였음을 알 수 있다.


<br/>
<br/>
<br/>

**Applying arithmetic in the input space**
![8 Glasses](https://user-images.githubusercontent.com/55128069/218315437-f5a385c0-54f4-4195-87e1-0d1f53037a11.png)

![7 Smilling](https://user-images.githubusercontent.com/55128069/218315433-93b8882c-c2bb-44c4-bf62-84a32af72b1c.png)

벡터 산술 연산을 통해 
vec(웃는 여자) - vec(무표정 여자) + vec(무표정 남자) = vec(웃는남자)
같은 결과를 얻을 수 있다.



<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

reference 

https://angrypark.github.io/generative%20models/paper%20review/2017/08/03/DCGAN-paper-reading/#applying-arithmetic-in-the-input-space

https://www.youtube.com/watch?v=7btUjE2y4NA&t=1023s









